{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://thevalley.es/wp-content/uploads/2016/11/thevalley-logo-negro.png\" width=\"400\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introducción al algoritmo de los k vecinos más próximos\n",
    "\n",
    "Notebook por \n",
    "[David Rey Blanco](https://www.linkedin.com/in/davidreyblanco).\n",
    "*Recursos*: Los códigos de esta sesión y recursos se pueden encontra en el [repositorio](https://github.com/davidreyblanco/ml-training) \n",
    "<br/>\n",
    "<hr/>\n",
    "\n",
    "El algoritmo de los K-Nearest-Neighbors o *K-Vecinos* es un algoritmo basado en instancias (o vago) y de tipo supervisado de Machine Learning. Puede usarse para clasificar elemementos (valores discretos) o para predecir valores continuos(regresión, valores continuos). \n",
    "\n",
    "Es un algoritmo muy usado, y es simple, fácil de entender, *fácil de interpretar*, versátil y uno de los mejores de aprendizaje automático. KNN se utiliza en una amplia gama de aplicaciones como finanzas, salud, ciencias políticas, detección de escritura, reconocimiento de imágenes y video. \n",
    "\n",
    "## Algoritmos vagos versus voraces\n",
    "\n",
    "Los algoritmos voraces (o ávidos de datos) son capaces de contruir un modelo  antes de realizar predicciones sobre nuevos puntos dados para clasificar. Puede pensar en estos algoritmos como si estuvieran preparados, activos y deseosos de clasificar los puntos de datos no observados.\n",
    "\n",
    "Los algoritmos vagos (o perezosos) significa que no hay necesidad de aprender o entrenar el modelo y todos los puntos de datos usados en el momento de la predicción. Los estudiantes perezosos esperan hasta el último minuto antes de clasificar cualquier punto de datos. El alumno perezoso almacena simplemente el conjunto de datos de entrenamiento y espera hasta que se deba realizar la clasificación. Solo cuando ve la tupla de prueba, realiza una generalización para clasificar la tupla en función de su similitud con las tuplas de entrenamiento almacenadas. A diferencia de los métodos de aprendizaje ávidos, los estudiantes perezosos hacen menos trabajo en la fase de formación y más trabajo en la fase de prueba para hacer una clasificación. Los estudiantes perezosos también se conocen como estudiantes basados ​​en instancias porque los estudiantes perezosos almacenan los puntos o instancias de capacitación, y todo el aprendizaje se basa en instancias.\n",
    "\n",
    "## El algoritmo KNN\n",
    "KNN es un algoritmo de aprendizaje vago y no paramétrico. No paramétrico significa que no hay suposiciones para la distribución de datos subyacente. En otras palabras, la estructura del modelo determinada a partir del conjunto de datos. Esto será muy útil en la práctica donde la mayoría de los conjuntos de datos del mundo real no siguen supuestos teóricos matemáticos. El algoritmo perezoso significa que no necesita ningún punto de datos de entrenamiento para la generación del modelo. Todos los datos de entrenamiento utilizados en la fase de prueba. Esto hace que el entrenamiento sea más rápido y la fase de prueba más lenta y costosa. La costosa fase de prueba significa tiempo y memoria. En el peor de los casos, KNN necesita más tiempo para escanear todos los puntos de datos y escanear todos los puntos de datos requerirá más memoria para almacenar los datos de entrenamiento.\n",
    "\n",
    "![Imagen](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531424125/Knn_k1_z96jba.png)\n",
    "\n",
    "Suponga que P1 es el punto, para el cual la etiqueta necesita predecir. Primero, encuentra el k punto más cercano a P1 y luego clasifica los puntos por voto mayoritario de sus k vecinos. Cada objeto vota por su clase y la clase con más votos se toma como predicción. Para encontrar puntos similares más cercanos, encuentre la distancia entre puntos utilizando medidas de distancia como la distancia euclidiana, la distancia de Hamming, la distancia de Manhattan y la distancia de Minkowski. \n",
    "\n",
    "Nuestro algoritmo sigue estos tres pasos:\n",
    "\n",
    "* Calcular la distancia\n",
    "* Encuentra los K vecinos más cercanos \n",
    "* Votación para la selección de la clase \n",
    "\n",
    "![Imagen](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531424125/KNN_final1_ibdm8a.png)\n",
    "\n",
    "\n",
    "### ¿Cómo funciona el algoritmo KNN?\n",
    "\n",
    "En KNN, K es el número de vecinos más cercanos. El número de vecinos es el factor decisivo fundamental. K es generalmente un número impar si el número de clases es 2. Cuando K = 1, entonces el algoritmo se conoce como el algoritmo de vecino más cercano. Este es el caso más simple. Suponga que P1 es el punto, para el cual la etiqueta necesita predecir. Primero, busque el punto más cercano a P1 y luego la etiqueta del punto más cercano asignado a P1.\n",
    "\n",
    "### La maldición de la dimensionalidad\n",
    "\n",
    "KNN funciona mejor con una menor cantidad de variables que una gran cantidad de variables. Se puede decir que cuando aumenta el número de funciones, se requieren más datos, de forma que el incremento de las dimensiones también conduce al problema del sobreajuste. Para evitar el sobreajuste, los datos necesarios deberán crecer exponencialmente a medida que aumente el número de dimensiones (y esto como se puede suponer tiene un claro impacto en los tiempos de ejecución y la memoria necesaria). A este problema se lo conoce como **la maldición de la dimensionalidad**.\n",
    "\n",
    "Para atacar el problema de la maldición de la dimensionalidad, debe pueden realizar actividades que nos reduzcan el número de dimensiones como un análisis de componentes principales antes de aplicar nuestro algoritmo de aprendizaje automático, o también puede usar el enfoque de selección de características (ambas no dejan de ser formas de reducir nuestro espacio de características de un número alto a un número más bajo, asegurando que la pérdida de información sea mínima y nuestros modelos no pierdan precisión). Es importante tener en cuenta que en múltiples artículos de investigación se ha demostrado que en grandes dimensiones la distancia euclidiana ya no es útil. Por lo tanto, es muy importante la decisión que medida es más apropiada. Como hemos visto en el módulo de distancias en casos de alta dimensionalidad y espacios dispersos puede ser muy interesante usar la similitud del coseno en lugar de la euclídea porque es menos sensible al impacto de la alta dimensionalidad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjuntos de datos\n",
    "(https://www.openml.org/s/76/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Importamos  train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Tranformación de variables\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Ignoramos los warning que no quedan muy bien\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Una primera aproximación al algoritmo de k-vecinos\n",
    "\n",
    "Vamos a hacer una primera prueba del algoritmo de k-vecinos con un primer clasificador de animales en función del peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos  de librerías\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gato']\n",
      "['tigre']\n",
      "[[1. 0.]]\n",
      "[[0.33333333 0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "Peso = [[2.5], [1.3], [0.8], [3.3],[120],[150],[210]]\n",
    "# 1 -> Gato\n",
    "# 2 -> Tigre\n",
    "clase = ['gato', 'gato', 'gato', 'gato', 'tigre', 'tigre','tigre']\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(Peso, clase)\n",
    "print(neigh.predict([[2.3]]))\n",
    "print(neigh.predict([[199]]))\n",
    "# Estimamos la probabilidad par aun animal de 2.3 kg\n",
    "print(neigh.predict_proba([[2.3]]))\n",
    "# Y si nos encontramos un animal del 80kg\n",
    "print(neigh.predict_proba([[80]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jugando con las medidas de distancia\n",
    "\n",
    "Vamos a poner a prueba nuestros conocimientos uniform le da la misma importancia a todas las instancias *(weights=uniform)*, que es el valor por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gato']\n",
      "['gato']\n"
     ]
    }
   ],
   "source": [
    "Peso = [[2.5], [1.3], [0.8], [3.3],[190]]\n",
    "clase = ['gato', 'gato', 'gato', 'gato', 'tigre']\n",
    "neigh = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "neigh.fit(Peso, clase)\n",
    "print(neigh.predict([[2.3]]))\n",
    "print(neigh.predict([[199]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pregunta)* ¿Qué está pasando ....?\n",
    "\n",
    "Ahora vamos a probar con una versión del método que asigna un peso mayor a la instancia cuanto más cerca este de nuestro dato de entrada *(weights=distance)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Peso = [[2.5], [1.3], [0.8], [3.3],[190]]\n",
    "clase = ['gato', 'gato', 'gato', 'gato', 'tigre']\n",
    "neigh = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "neigh.fit(Peso, clase)\n",
    "print(neigh.predict([[2.3]]))\n",
    "print(neigh.predict([[199]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El efecto de la normalización / estandarización de variables\n",
    "\n",
    "Vamos a ver el efecto de la estandarización en la clasificación, ahora usaremos un ejemplo en el que tenemos un a lista de clientes, cada uno con dos atributos y una clase:\n",
    "\n",
    "    * Gasto anual en euros\n",
    "    * Edad\n",
    "    * Clase: starter, senior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gasto</th>\n",
       "      <th>edad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1350</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1550</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1400</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1600</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1400</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1120</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gasto  edad\n",
       "0   1200    30\n",
       "1   1350    35\n",
       "2   1550    60\n",
       "3   1400    55\n",
       "4   1600    75\n",
       "5   1400    20\n",
       "6   1120    25"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos el algoritmo estandarizando las columnas\n",
    "clientes = [[1200,30], [1350,35], [1550,60], [1400,55],[1600,75],[1400,20],[1120,25]]\n",
    "clase_cliente = ['starter','starter','senior','senior','senior','starter','starter']\n",
    "df = pd.DataFrame(clientes, columns=['gasto','edad'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos nuestro modelo basado en los K=2 vecinos más cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['senior' 'starter']\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "neigh.fit(clientes, clase_cliente)\n",
    "clientes_nuevos = [[1450,28], [1185,74]]\n",
    "print(neigh.predict(clientes_nuevos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver si cambia si normalizamos los datos ver las funciones es https://scikit-learn.org/stable/modules/preprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gasto</th>\n",
       "      <th>edad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.090591</td>\n",
       "      <td>-0.674579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.151968</td>\n",
       "      <td>-0.412242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.099530</td>\n",
       "      <td>0.899438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.160907</td>\n",
       "      <td>0.637102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.412404</td>\n",
       "      <td>1.686446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.160907</td>\n",
       "      <td>-1.199251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.591190</td>\n",
       "      <td>-0.936915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gasto      edad\n",
       "0 -1.090591 -0.674579\n",
       "1 -0.151968 -0.412242\n",
       "2  1.099530  0.899438\n",
       "3  0.160907  0.637102\n",
       "4  1.412404  1.686446\n",
       "5  0.160907 -1.199251\n",
       "6 -1.591190 -0.936915"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un transformador\n",
    "scaler_df = preprocessing.StandardScaler().fit(df.values)\n",
    "# Re escalamos el conjunto de entrada\n",
    "array_clientes_scaled = scaler_df.transform(df.values)\n",
    "df_scaled = pd.DataFrame(array_clientes_scaled, columns=['gasto','edad'])\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y re escalamos también los clientes nuevos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47378117, -0.77951296],\n",
       "       [-1.18445292,  1.63397908]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re escalamos el conjunto de clasificación\n",
    "clientes_nuevos_scaled = scaler_df.transform(clientes_nuevos)\n",
    "clientes_nuevos_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a clasificar nuestros casos y vemos como en este caso la edad no está *discriminada* por su escala y tenemos un valor más razonable para la clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['starter' 'senior']\n"
     ]
    }
   ],
   "source": [
    "# Transformamos los clientes originales\n",
    "clientes_nuevos_scaled = scaler_df.fit_transform(clientes_nuevos)\n",
    "neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "neigh.fit(df_scaled.values, clase_cliente)\n",
    "# Recordamos el \n",
    "#clientes_nuevos = [[1450,28], [1185,74]]\n",
    "print(neigh.predict(clientes_nuevos_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pregunta)* ¿Y por qué ahora funciona *bien*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de clasificación multiclase\n",
    "\n",
    "Hasta ahora, ha aprendido a crear un clasificador KNN para dos en python usando scikit-learn. Ahora aprenderá sobre KNN con múltiples clases.\n",
    "\n",
    "En el modelo de la parte de construcción, puede utilizar el conjunto de datos de vino, que es un problema de clasificación de clases múltiples muy famoso. Estos datos son el resultado de un análisis químico de vinos cultivados en la misma región en Italia utilizando tres cultivares diferentes. El análisis determinó las cantidades de 13 componentes que se encuentran en cada uno de los tres tipos de vinos.\n",
    "\n",
    "El conjunto de datos comprende 13 características ('alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline')  y un objetivo (tipo de cultivares).\n",
    "\n",
    "Estos datos tienen tres tipos de clases de cultivares: 'class_0', 'class_1' y 'class_2'. Aquí, puede construir un modelo para clasificar el tipo de cultivo. El conjunto de datos está disponible en la biblioteca scikit-learn, o también puede descargarlo de la biblioteca de aprendizaje automático de UCI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Cargamos los datos del paquete sckitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "#Load dataset\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración básica\n",
    "\n",
    "Una vez que haya cargado el conjunto de datos, es posible que desee saber un poco más sobre él. Puede comprobar los nombres de las funciones y los objetivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "# Mostrar características\n",
    "print(wine.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "# Mostramos las clases objetivo\n",
    "print(wine.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos las 3 primeras instancias del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 1.120e+01 1.000e+02 2.650e+00 2.760e+00\n",
      "  2.600e-01 1.280e+00 4.380e+00 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
      "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(wine.data[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check records of the target set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore it for a bit more. You can also check the shape of the dataset using shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de conjuntos de entrenamiento y validación\n",
    "\n",
    "Para comprender el rendimiento del modelo, dividir el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba es una buena estrategia.\n",
    "\n",
    "Dividamos el conjunto de datos usando la función train_test_split (). Debe pasar 3 parámetros, características, destino y tamaño del conjunto de pruebas. Además, puede usar random_state para seleccionar registros al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set 70% train/ 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación del modelo para K=5\n",
    "Elegimos una K que se nos ocurra, por ejemplo K=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create KNN Classifier\n",
    "K=5\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo para k = 5\n",
    "Calculemos con qué precisión el clasificador o modelo puede predecir el tipo de cultivares.\n",
    "\n",
    "La precisión se puede calcular comparando los valores reales del conjunto de prueba y los valores predichos.\n",
    "\n",
    "La exactitud es una métrica para evaluar modelos de clasificación. Informalmente, la exactitud es la fracción de predicciones que el modelo realizó correctamente. Formalmente, la exactitud tiene la siguiente definición:\n",
    "\n",
    "En la clasificación binaria, la exactitud (accuracy) también se puede calcular en términos de positivos y negativos de la siguiente manera:\n",
    "$$\n",
    "    Accuracy = \\frac{Verdaderos Positivos + Verdaderos Negativos}{Total\\ casos}\n",
    "$$\n",
    "\n",
    "https://developers.google.com/machine-learning/crash-course/classification/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo se decide el número de vecinos en KNN?\n",
    "\n",
    "Ahora que ya entendemos el funcionamiento del algoritmo, surge la pregunta ¿Cómo elegir el número óptimo de vecinos? ¿Y cuáles son sus efectos sobre el clasificador? El número de vecinos (K) en KNN es un hiperparámetro que debe elegir en el momento de la construcción del modelo. Puede pensar en K como una variable de control para el modelo de predicción.\n",
    "\n",
    "La investigación ha demostrado que no existe un K óptimo de vecinos que se ajuste a todo tipo de conjuntos de datos. Cada conjunto de datos tiene sus propios requisitos. En el caso de un pequeño número de vecinos, el ruido tendrá una mayor influencia en el resultado y un gran número de vecinos lo hace computacionalmente costoso. La investigación también ha demostrado que una pequeña cantidad de vecinos tienen un ajuste más flexible, lo que tendrá un sesgo bajo pero una varianza alta, y un gran número de vecinos tendrá un límite de decisión más suave, lo que significa una varianza menor pero un sesgo más alto.\n",
    "\n",
    "Generalmente, los científicos de datos eligen como un número impar si el número de clases es par. También puede verificar generando el modelo en diferentes valores de ky verificar su desempeño. También puedes probar el método del codo aquí.\n",
    "\n",
    "![Imagen](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531424125/KNN_final_a1mrv9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud (accuracy) K=3:  0.7407407407407407\n",
      "Exactitud (accuracy) K=4:  0.7222222222222222\n",
      "Exactitud (accuracy) K=5:  0.7037037037037037\n",
      "Exactitud (accuracy) K=6:  0.7037037037037037\n",
      "Exactitud (accuracy) K=7:  0.7222222222222222\n",
      "Exactitud (accuracy) K=8:  0.7222222222222222\n",
      "Exactitud (accuracy) K=9:  0.6851851851851852\n",
      "Mejor según accuracy: K=3\n"
     ]
    }
   ],
   "source": [
    "#Create KNN Classifier\n",
    "best_k = 0\n",
    "best_accuracy = 0\n",
    "for K in range(3,10):\n",
    "    knn = KNeighborsClassifier(n_neighbors=K)\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = knn.predict(X_test)\n",
    "    #Import scikit-learn metrics module for accuracy calculation\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"Exactitud (accuracy) K=\"+str(K)+\": \",accuracy)\n",
    "    if best_accuracy < accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_k = K\n",
    "print('Mejor según accuracy: K=' + str(best_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo de sensibles somos a la falta de información?\n",
    "Estos algoritmos son muy sensibles a la falta de información, ¿estamos seguros de que estos resultados son correctos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor según accuracy: K=6 en iteración:9\n"
     ]
    }
   ],
   "source": [
    "best_iteration = 0\n",
    "best_k = 0\n",
    "best_accuracy = 0\n",
    "for iteration in range(1,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.3) \n",
    "    for K in range(3,10):\n",
    "        knn = KNeighborsClassifier(n_neighbors=K)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        #print(\"Exactitud [\"+str(iteration)+\"] (accuracy) K=\"+str(K)+\": \",accuracy)\n",
    "        if best_accuracy < accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_k = K\n",
    "            best_iteration = iteration\n",
    "            \n",
    "print('Mejor según accuracy: K=' + str(best_k)+ ' en iteración:' + str(iteration))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preguntas**: \n",
    "* *¿Qué puede estar pasando?*\n",
    "* *¿que pasa si cambiamos el test_size a un 10% o a un 50%?, qué pasa en cada caso*\n",
    "* *¿Cómo podríamos tener un mecanismo más robusto para la selección de la K?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efecto de la optimización en la búsqueda (ball tree, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exploring Data\n",
    "After you have loaded the dataset, you might want to know a little bit more about it. You can check feature and target names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de regresión\n",
    "\n",
    "El modelo de regresión en esencia es muy parecido al de clasificación, pero en este caso buscamos una salida numérica, para calcularla la *votación* del resultado final puede ser una media, media ponderada, mediana o la medida que nos pueda interesar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo de felices somos en España?\n",
    "¿A qué alguna vez nos hemos preguntado si somos felices o no?, vamos a intentar hacer un modelo con lo que hemos aprendido en esta clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de entrada\n",
    "\n",
    "Para este caso vamos a usar los datos de felicidad en el mundo. Que de nuevo un reto procedente de un dataset de Kaggle, en este caso tenemos las clasificaciones de felicidad por país. \n",
    "\n",
    "Las puntuaciones y clasificaciones de felicidad utilizan datos de la Encuesta Mundial de Gallup. Los puntajes se basan en las respuestas a la pregunta principal de evaluación de la vida que se hizo en la encuesta. Esta pregunta, conocida como *la escala de Cantril*, pide a los encuestados que piensen en una escala en la que la mejor vida posible para ellos sea un 10 y la peor vida posible sea un 0 y que califiquen sus propias vidas actuales en esa escala. Los puntos provienen de muestras representativas a nivel nacional para los años 2013-2016 y utilizan las ponderaciones de Gallup para hacer las estimaciones representativas. \n",
    "\n",
    "Las columnas que siguen al puntos de felicidad estiman en qué medida cada uno de los seis factores (producción económica, apoyo social, esperanza de vida, libertad, ausencia de corrupción y generosidad) contribuyen a hacer que las evaluaciones de vida sean más altas en cada país que en *Distopía*, un país hipotético que tiene valores iguales a los promedios nacionales más bajos del mundo para cada uno de los seis factores. No tienen ningún impacto en la puntuación total informada para cada país, pero sí explican por qué algunos países tienen una clasificación más alta que otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_rank</th>\n",
       "      <th>country_or_region</th>\n",
       "      <th>score</th>\n",
       "      <th>gdp_per_capita</th>\n",
       "      <th>social_support</th>\n",
       "      <th>healthy_life_expectancy</th>\n",
       "      <th>freedom_to_make_life_choices</th>\n",
       "      <th>generosity</th>\n",
       "      <th>perceptions_of_corruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Finland</td>\n",
       "      <td>7.769</td>\n",
       "      <td>1.340</td>\n",
       "      <td>1.587</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>7.600</td>\n",
       "      <td>1.383</td>\n",
       "      <td>1.573</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Norway</td>\n",
       "      <td>7.554</td>\n",
       "      <td>1.488</td>\n",
       "      <td>1.582</td>\n",
       "      <td>1.028</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>7.494</td>\n",
       "      <td>1.380</td>\n",
       "      <td>1.624</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>7.488</td>\n",
       "      <td>1.396</td>\n",
       "      <td>1.522</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall_rank country_or_region  score  gdp_per_capita  social_support  \\\n",
       "0             1           Finland  7.769           1.340           1.587   \n",
       "1             2           Denmark  7.600           1.383           1.573   \n",
       "2             3            Norway  7.554           1.488           1.582   \n",
       "3             4           Iceland  7.494           1.380           1.624   \n",
       "4             5       Netherlands  7.488           1.396           1.522   \n",
       "\n",
       "   healthy_life_expectancy  freedom_to_make_life_choices  generosity  \\\n",
       "0                    0.986                         0.596       0.153   \n",
       "1                    0.996                         0.592       0.252   \n",
       "2                    1.028                         0.603       0.271   \n",
       "3                    1.026                         0.591       0.354   \n",
       "4                    0.999                         0.557       0.322   \n",
       "\n",
       "   perceptions_of_corruption  \n",
       "0                      0.393  \n",
       "1                      0.410  \n",
       "2                      0.341  \n",
       "3                      0.118  \n",
       "4                      0.298  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hapiness = pd.read_csv('https://raw.githubusercontent.com/davidreyblanco/ml-training/master/data/happiness_2019.csv')\n",
    "# Limpiamos un poco los nombres de las columnas para eliminar espacios y mayúsculas\n",
    "df_hapiness.columns = df_hapiness.columns.str.replace(' ', '_')\n",
    "df_hapiness.columns = df_hapiness.columns.str.lower()\n",
    "df_hapiness.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos unos mínimos descriptivos por un lado los datos numéricos y las columnas del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['overall_rank', 'country_or_region', 'score', 'gdp_per_capita',\n",
       "       'social_support', 'healthy_life_expectancy',\n",
       "       'freedom_to_make_life_choices', 'generosity',\n",
       "       'perceptions_of_corruption'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hapiness.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_rank</th>\n",
       "      <th>score</th>\n",
       "      <th>gdp_per_capita</th>\n",
       "      <th>social_support</th>\n",
       "      <th>healthy_life_expectancy</th>\n",
       "      <th>freedom_to_make_life_choices</th>\n",
       "      <th>generosity</th>\n",
       "      <th>perceptions_of_corruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78.500000</td>\n",
       "      <td>5.407096</td>\n",
       "      <td>0.905147</td>\n",
       "      <td>1.208814</td>\n",
       "      <td>0.725244</td>\n",
       "      <td>0.392571</td>\n",
       "      <td>0.184846</td>\n",
       "      <td>0.110603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45.177428</td>\n",
       "      <td>1.113120</td>\n",
       "      <td>0.398389</td>\n",
       "      <td>0.299191</td>\n",
       "      <td>0.242124</td>\n",
       "      <td>0.143289</td>\n",
       "      <td>0.095254</td>\n",
       "      <td>0.094538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.853000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.750000</td>\n",
       "      <td>4.544500</td>\n",
       "      <td>0.602750</td>\n",
       "      <td>1.055750</td>\n",
       "      <td>0.547750</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.108750</td>\n",
       "      <td>0.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78.500000</td>\n",
       "      <td>5.379500</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.271500</td>\n",
       "      <td>0.789000</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.085500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>117.250000</td>\n",
       "      <td>6.184500</td>\n",
       "      <td>1.232500</td>\n",
       "      <td>1.452500</td>\n",
       "      <td>0.881750</td>\n",
       "      <td>0.507250</td>\n",
       "      <td>0.248250</td>\n",
       "      <td>0.141250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>156.000000</td>\n",
       "      <td>7.769000</td>\n",
       "      <td>1.684000</td>\n",
       "      <td>1.624000</td>\n",
       "      <td>1.141000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.453000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall_rank       score  gdp_per_capita  social_support  \\\n",
       "count    156.000000  156.000000      156.000000      156.000000   \n",
       "mean      78.500000    5.407096        0.905147        1.208814   \n",
       "std       45.177428    1.113120        0.398389        0.299191   \n",
       "min        1.000000    2.853000        0.000000        0.000000   \n",
       "25%       39.750000    4.544500        0.602750        1.055750   \n",
       "50%       78.500000    5.379500        0.960000        1.271500   \n",
       "75%      117.250000    6.184500        1.232500        1.452500   \n",
       "max      156.000000    7.769000        1.684000        1.624000   \n",
       "\n",
       "       healthy_life_expectancy  freedom_to_make_life_choices  generosity  \\\n",
       "count               156.000000                    156.000000  156.000000   \n",
       "mean                  0.725244                      0.392571    0.184846   \n",
       "std                   0.242124                      0.143289    0.095254   \n",
       "min                   0.000000                      0.000000    0.000000   \n",
       "25%                   0.547750                      0.308000    0.108750   \n",
       "50%                   0.789000                      0.417000    0.177500   \n",
       "75%                   0.881750                      0.507250    0.248250   \n",
       "max                   1.141000                      0.631000    0.566000   \n",
       "\n",
       "       perceptions_of_corruption  \n",
       "count                 156.000000  \n",
       "mean                    0.110603  \n",
       "std                     0.094538  \n",
       "min                     0.000000  \n",
       "25%                     0.047000  \n",
       "50%                     0.085500  \n",
       "75%                     0.141250  \n",
       "max                     0.453000  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hapiness.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construimos los datos de entrada\n",
    "Seleccionamos los datos del resto del mundo como datos para construir el modelo y el de España para evaluar nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a construir un modelo de regresión en el que sacamos a España del conjunto de entrada\n",
    "df_spain = df_hapiness[(df_hapiness.country_or_region == \"Spain\")]\n",
    "df_world = df_hapiness[(df_hapiness.country_or_region != \"Spain\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos nuestras caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos nuestras features para el conjunto de entrada\n",
    "feature_set = ['gdp_per_capita',\n",
    "       'social_support', 'healthy_life_expectancy',\n",
    "       'freedom_to_make_life_choices', 'generosity',\n",
    "       'perceptions_of_corruption']\n",
    "df_train_features = df_world[feature_set]\n",
    "df_train_target = df_world['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versión naive de nuestro algoritmo\n",
    "Construimos un algoritmo de regresión usando los 3 países más parecidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "          weights='uniform')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "K = 3\n",
    "# Repaso: Minkowski con p = 2 es la distancia euclídea\n",
    "happiness_model = KNeighborsRegressor(n_neighbors=K,\n",
    "                    weights='uniform',\n",
    "                    p=2, \n",
    "                    metric='minkowski')  \n",
    "\n",
    "# Construimos nuestro modelo\n",
    "happiness_model.fit(df_train_features.values, df_train_target.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora vamos a ver como somos de felices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.65133333])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "input_spain = df_spain[feature_set].values\n",
    "happiness_spain = happiness_model.predict(input_spain)\n",
    "happiness_spain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo hemos sido de precisos en nuestra predicción de felicidad?, para eso calculamos una medida de error como el error en porcentaje calculado como:\n",
    "    $$\n",
    "    MAPE = \\frac{abs(y - \\hat{y})}{y}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuestra predicción se desvía un 4.679% del valor real\n"
     ]
    }
   ],
   "source": [
    "actual_happiness = df_spain['score'].values\n",
    "pct_error = 100*abs(actual_happiness[0] -  happiness_spain[0]) / actual_happiness[0]\n",
    "print('Nuestra predicción se desvía un ' + str(round(pct_error,3)) + '% del valor real')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver si nuestro algoritmo ha funcionado bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_rank</th>\n",
       "      <th>country_or_region</th>\n",
       "      <th>score</th>\n",
       "      <th>gdp_per_capita</th>\n",
       "      <th>social_support</th>\n",
       "      <th>healthy_life_expectancy</th>\n",
       "      <th>freedom_to_make_life_choices</th>\n",
       "      <th>generosity</th>\n",
       "      <th>perceptions_of_corruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Spain</td>\n",
       "      <td>6.354</td>\n",
       "      <td>1.286</td>\n",
       "      <td>1.484</td>\n",
       "      <td>1.062</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    overall_rank country_or_region  score  gdp_per_capita  social_support  \\\n",
       "29            30             Spain  6.354           1.286           1.484   \n",
       "\n",
       "    healthy_life_expectancy  freedom_to_make_life_choices  generosity  \\\n",
       "29                    1.062                         0.362       0.153   \n",
       "\n",
       "    perceptions_of_corruption  \n",
       "29                      0.079  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué ejemplos hemos usado para clasificar?, vemos por un lado las medidas de distancia y por otro lado las posiciones en el array del conjunto de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.11740528, 0.14118428, 0.14211263]]), array([[12, 23, 34]]))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = happiness_model.kneighbors(input_spain, n_neighbors = K)\n",
    "neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿A quién nos parecemos?, pues la segunda poscición del array anterior lo vemos y creo que no nos llevaremos ninguna sorpresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_rank</th>\n",
       "      <th>country_or_region</th>\n",
       "      <th>score</th>\n",
       "      <th>gdp_per_capita</th>\n",
       "      <th>social_support</th>\n",
       "      <th>healthy_life_expectancy</th>\n",
       "      <th>freedom_to_make_life_choices</th>\n",
       "      <th>generosity</th>\n",
       "      <th>perceptions_of_corruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Israel</td>\n",
       "      <td>7.139</td>\n",
       "      <td>1.276</td>\n",
       "      <td>1.455</td>\n",
       "      <td>1.029</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>France</td>\n",
       "      <td>6.592</td>\n",
       "      <td>1.324</td>\n",
       "      <td>1.472</td>\n",
       "      <td>1.045</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>Italy</td>\n",
       "      <td>6.223</td>\n",
       "      <td>1.294</td>\n",
       "      <td>1.488</td>\n",
       "      <td>1.039</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    overall_rank country_or_region  score  gdp_per_capita  social_support  \\\n",
       "12            13            Israel  7.139           1.276           1.455   \n",
       "23            24            France  6.592           1.324           1.472   \n",
       "35            36             Italy  6.223           1.294           1.488   \n",
       "\n",
       "    healthy_life_expectancy  freedom_to_make_life_choices  generosity  \\\n",
       "12                    1.029                         0.371       0.261   \n",
       "23                    1.045                         0.436       0.111   \n",
       "35                    1.039                         0.231       0.158   \n",
       "\n",
       "    perceptions_of_corruption  \n",
       "12                      0.082  \n",
       "23                      0.183  \n",
       "35                      0.030  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_world.iloc[neighbors[1][0], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Podríamos afinar un poco más?\n",
    "Hemos usado la medida de pesos uniforme (es decir damos el mismo peso a cualquiera de las K instancias), pero vamos a probar a hacer una predicción dandole un peso inversamente proporcional a al distancia a las instancias. Así que usaremos todas *nuestras armas* que ya hemos aprendido hoy:\n",
    "\n",
    "* Escalado de variables\n",
    "* Pesos en función de la distancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "          metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "          weights='distance')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 3\n",
    "happiness_model = KNeighborsRegressor(n_neighbors=K,\n",
    "                    weights='distance',\n",
    "                    metric='euclidean')\n",
    "\n",
    "scaler_happiness = preprocessing.StandardScaler().fit(df_train_features)\n",
    "scaled_features = scaler_happiness.transform(df_train_features)\n",
    "\n",
    "# Construimos nuestro modelo\n",
    "happiness_model.fit(scaled_features, df_train_target.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimamos nuestro score de felicidad entre 1 y 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.25184763])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "input_spain = scaler_happiness.transform(df_spain[feature_set].values)\n",
    "happiness_spain = happiness_model.predict(input_spain)\n",
    "happiness_spain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos una medida de error como el error en porcentaje calculado como:\n",
    "    $$\n",
    "    MAPE = \\frac{abs(y - \\hat{y})}{y}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuestra predicción se desvía un 1.608% del valor real\n"
     ]
    }
   ],
   "source": [
    "actual_happiness = df_spain['score'].values\n",
    "pct_error = 100*abs(actual_happiness[0] -  happiness_spain[0]) / actual_happiness[0]\n",
    "print('Nuestra predicción se desvía un ' + str(round(pct_error,3)) + '% del valor real')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos ahora a quien nos parecemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_rank</th>\n",
       "      <th>country_or_region</th>\n",
       "      <th>score</th>\n",
       "      <th>gdp_per_capita</th>\n",
       "      <th>social_support</th>\n",
       "      <th>healthy_life_expectancy</th>\n",
       "      <th>freedom_to_make_life_choices</th>\n",
       "      <th>generosity</th>\n",
       "      <th>perceptions_of_corruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Chile</td>\n",
       "      <td>6.444</td>\n",
       "      <td>1.159</td>\n",
       "      <td>1.369</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>Italy</td>\n",
       "      <td>6.223</td>\n",
       "      <td>1.294</td>\n",
       "      <td>1.488</td>\n",
       "      <td>1.039</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>6.046</td>\n",
       "      <td>1.263</td>\n",
       "      <td>1.223</td>\n",
       "      <td>1.042</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    overall_rank country_or_region  score  gdp_per_capita  social_support  \\\n",
       "25            26             Chile  6.444           1.159           1.369   \n",
       "35            36             Italy  6.223           1.294           1.488   \n",
       "48            49            Cyprus  6.046           1.263           1.223   \n",
       "\n",
       "    healthy_life_expectancy  freedom_to_make_life_choices  generosity  \\\n",
       "25                    0.920                         0.357       0.187   \n",
       "35                    1.039                         0.231       0.158   \n",
       "48                    1.042                         0.406       0.190   \n",
       "\n",
       "    perceptions_of_corruption  \n",
       "25                      0.056  \n",
       "35                      0.030  \n",
       "48                      0.041  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = happiness_model.kneighbors(input_spain, n_neighbors = K)\n",
    "df_world.iloc[neighbors[1][0], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hemos mejorado sensiblemente nuestra predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La maldición del big data y la dimensionalidad\n",
    "A veces tener muchos datos más que una bendición es una maldición, para resolver este problema scikit learn utiliza una serie de algoritmos para la búsqueda de la información que nos ayudan a ser eficientes, repaso sobre los algoritmos disponibles en scikit learn:\n",
    "\n",
    "**Algoritmos disponibles** [Referencia sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor.kneighbors): \n",
    "\n",
    "* ‘ball_tree’ will use BallTree\n",
    "\n",
    "* ‘kd_tree’ will use KDTree\n",
    "\n",
    "* ‘brute’ will use a brute-force search.\n",
    "\n",
    "* ‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.\n",
    "\n",
    "**Importante**: El entrenamiento en datos dispersos usará siempre el modo brute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La fuerza bruta\n",
    "La fuerza bruta a no ser que seas muy bruto no suele ser la mejor estrategia, en este caso usamos %%time para mostrar el tiempo de ejecución (hace una simulación). Se muestran varios tiempos:\n",
    "\n",
    "* *wall time*: es el tiempo real que le lleva al programa entre que arranca hasta que termina\n",
    "* *cpu time*: o el tiempo que dedica la CPU a ejecutar el proceso, si existe paralelismo este puede ser mayor al wall time\n",
    "\n",
    "Como el conjunto de entrada es relativamente pequeño (155 instancias), vamos a ponerselo un poco dificil al algoritmo y a aumentaremos por 50 el numero de registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7905"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_big_world = df_world\n",
    "df_big_world = df_big_world.append([df_big_world]*50,ignore_index=True)\n",
    "df_train_features = df_big_world[feature_set]\n",
    "df_train_target = df_big_world['score']\n",
    "len(df_big_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.19 ms, sys: 65 µs, total: 2.25 ms\n",
      "Wall time: 1.48 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Entrenamiento (si queremos llamarlo así)\n",
    "K = 5\n",
    "happiness_model = KNeighborsRegressor(n_neighbors=K,\n",
    "                    weights='uniform',\n",
    "                    algorithm='brute',\n",
    "                    p=2, \n",
    "                    metric='minkowski')  \n",
    "\n",
    "# Construimos nuestro modelo\n",
    "happiness_model.fit(df_train_features.values, df_train_target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.61 ms, sys: 32 ms, total: 37.6 ms\n",
      "Wall time: 8.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inferencia (si queremos llamarlo así)\n",
    "happiness_spain = happiness_model.predict(df_spain[feature_set].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendiendo con poco de sensatez KD Tree\n",
    "Usamos uno de los algoritmos, en este caso usaremos el árbol  ti po K-D [Árbol K-D](https://es.wikipedia.org/wiki/%C3%81rbol_kd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.77 ms, sys: 0 ns, total: 5.77 ms\n",
      "Wall time: 4.92 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Entrenamiento (si queremos llamarlo así)\n",
    "K = 5\n",
    "happiness_model = KNeighborsRegressor(n_neighbors=K,\n",
    "                    weights='uniform',\n",
    "                    algorithm='kd_tree',\n",
    "                    p=2, \n",
    "                    metric='minkowski')  \n",
    "\n",
    "# Construimos nuestro modelo\n",
    "happiness_model.fit(df_train_features.values, df_train_target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.22 ms, sys: 0 ns, total: 2.22 ms\n",
      "Wall time: 1.91 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inferencia (si queremos llamarlo así)\n",
    "happiness_spain = happiness_model.predict(df_spain[feature_set].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones sobre el uso de algoritmos para mejorar la búsqueda\n",
    "En este caso el conjunto de ejemplos es de cientos de instancias, varias preguntas:\n",
    "\n",
    "* *¿qué pasa con los tiempos de construcción del modelo (fit)*?\n",
    "* *¿y qué pasa con los tiempos de predicción (predict)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "[K-Neighbors Scikitlearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios propuestos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador de zonas gemelas\n",
    "Tenemos un listado de zonas en el municipio de Madrid, cada zona tiene una serie de características numéricas, eliminamos del conjunto de entrada los barrios Sol, ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciendo la felicidad\n",
    "\n",
    "Podemos predecir la felicidad de un país en base a sus características, el ejercicio consiste en eliminar Japón, España, Alemania y Argelia del conjunto de entrenamiento y crear un modelo de k-vecinos de regresión con el resto de instancias. Una una vez lo tenemos tenemos que calcular la fiabilidad  de nuestro modelo con dos tres métricas:\n",
    "\n",
    "* Error medio\n",
    "* Error mediano\n",
    "* Error cuadrático medio\n",
    "\n",
    "El error lo calculamos como *nivel de felicidad predicho - nivel de felicidad real*\n",
    "\n",
    "*Pregunta 1)* ¿Con que número k funciona mejor el algoritmo?\n",
    "\n",
    "*Pregunta 2)*¿Cual es el efecto de usar pesos inversamente proporcionales a la distancia a no usarlos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
